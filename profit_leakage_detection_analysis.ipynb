{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Profit Leakage Detection \u2014 Advanced Statistical Methods\n",
        "Integrated analysis using **Bayesian inference**, **Statistical Process Control (SPC)**, and **Bootstrapping** to detect margin anomalies and quantify uncertainty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt, pymc as pm, arviz as az\n",
        "df = pd.read_csv('data/service_orders_synthetic.csv', parse_dates=['order_dt'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bayesian Hierarchical Modeling\n",
        "We estimate region-level true mean margins with partial pooling:\n",
        "\\[ y_{ij} \\sim \\mathcal{N}(\\mu_i, \\sigma^2), \\quad \\mu_i \\sim \\mathcal{N}(\\mu_0, \\tau^2) \\]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y = df[['region','margin_pct']].dropna(); regions = y['region'].astype('category'); idx = regions.cat.codes.values; y_obs = y['margin_pct'].values\n",
        "with pm.Model() as model:\n",
        "    mu_overall = pm.Normal('mu_overall', mu=0.15, sigma=0.1)\n",
        "    sigma_group = pm.HalfNormal('sigma_group', sigma=0.1)\n",
        "    sigma = pm.HalfNormal('sigma', sigma=0.1)\n",
        "    mu_group = pm.Normal('mu_group', mu=mu_overall, sigma=sigma_group, shape=regions.cat.categories.size)\n",
        "    pm.Normal('y_like', mu=mu_group[idx], sigma=sigma, observed=y_obs)\n",
        "    idata = pm.sample(1000, tune=1000, target_accept=0.9, chains=2, cores=1, progressbar=False)\n",
        "az.summary(idata, var_names=['mu_overall','sigma_group','sigma','mu_group']).head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "post = az.extract(idata, var_names=['mu_group']).to_numpy()\n",
        "probs = (post < 0).mean(axis=0)\n",
        "pd.DataFrame({'region': regions.cat.categories, 'p_loss': probs}).sort_values('p_loss', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SPC \u2014 Shewhart and CUSUM Charts\n",
        "Tracks weekly mean margin% for stability and small persistent drifts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "weekly = (df.groupby(df['order_dt'].dt.isocalendar().week, as_index=False)\n",
        "            .agg(mean_margin=('margin_pct','mean')))\n",
        "weekly.columns=['week','mean_margin']\n",
        "m, s = weekly['mean_margin'].mean(), weekly['mean_margin'].std()\n",
        "ucl, lcl = m+3*s, m-3*s\n",
        "plt.figure(figsize=(10,4)); plt.plot(weekly['week'], weekly['mean_margin'], marker='o');\n",
        "plt.axhline(m, color='blue', linestyle='--'); plt.axhline(ucl, color='red', linestyle='--'); plt.axhline(lcl, color='red', linestyle='--');\n",
        "plt.title('Shewhart Control Chart'); plt.xlabel('Week'); plt.ylabel('Mean Margin%'); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "k = 0.5*s; h = 5*s; pos=[0]; neg=[0]; signals=[]\n",
        "for i, x in enumerate(weekly['mean_margin']):\n",
        "    pos.append(max(0, pos[-1] + (x - (m + k))))\n",
        "    neg.append(min(0, neg[-1] + (x - (m - k))))\n",
        "    if pos[-1] > h or neg[-1] < -h: signals.append(i)\n",
        "plt.figure(figsize=(8,4)); plt.plot(pos[1:], label='CUSUM+'); plt.plot(neg[1:], label='CUSUM-'); plt.legend(); plt.title('CUSUM Chart'); plt.show(); signals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bootstrapping Confidence Intervals for Loss Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "loss = (df['margin_amount']<0).astype(int)\n",
        "means = [loss.sample(frac=1, replace=True).mean() for _ in range(1000)]\n",
        "ci = np.percentile(means, [2.5, 97.5])\n",
        "plt.hist(means, bins=30, color='skyblue'); plt.axvline(ci[0], color='red'); plt.axvline(ci[1], color='red'); plt.title('Bootstrap 95% CI for Loss Rate'); plt.show(); ci"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Priority Scoring \u2014 Frequency \u00d7 Financial Impact"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "seg = (df.assign(loss=lambda x: x['margin_amount']<0)\n",
        "         .groupby(['region','job_code'], as_index=False)\n",
        "         .agg(orders=('service_order_no','count'), total_margin=('margin_amount','sum'), loss_rate=('loss','mean')))\n",
        "seg['priority'] = (-seg['total_margin'].clip(upper=0)) * (0.5 + seg['loss_rate'])\n",
        "top = seg.sort_values('priority', ascending=False).head(10)\n",
        "labels = top['region'] + ' | ' + top['job_code'].astype(str)\n",
        "plt.figure(figsize=(8,4)); plt.barh(labels, -top['total_margin']); plt.gca().invert_yaxis(); plt.title('Top 10 Loss Segments'); plt.tight_layout(); plt.show(); top"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}